{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86f846ab-0754-4e40-8912-3aa9b19edec9",
   "metadata": {},
   "source": [
    "# Testing StarDist network for instance segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c606305e-397e-47b2-8f36-6064372de8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"image.interpolation\"] = 'none'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import skimage as sk\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import Path, normalize\n",
    "import napari\n",
    "import os\n",
    "from stardist import fill_label_holes, random_label_cmap, calculate_extents, gputools_available\n",
    "from stardist.matching import matching, matching_dataset\n",
    "from stardist.models import Config2D, StarDist2D, StarDistData2D\n",
    "\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fdca24-f2aa-47f5-87ea-77c3c838a3d7",
   "metadata": {},
   "source": [
    "Use the following 2 cells to convert pngs of masks exported from QuPath to Tiffs, if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cf81ea-69dc-47ca-ad8f-0a2dda1cf71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PNGs = sorted(glob('E:/Grainger_Lab/Amber/OIC-74_Zebrafish_RBC_Classification/tiles/**/instTiles/*.png',recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa2288e-2e16-465b-a865-323216a5879b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converted all pngs to tiffs\n",
    "for y in PNGs:\n",
    "    path = os.path.dirname(y)\n",
    "    name = os.path.basename(y)\n",
    "    img = sk.io.imread(y)\n",
    "    sk.io.imsave(os.path.join(path,name[:-4]+'.tif'),img,check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d31203-1d3f-428f-a04e-89714da46631",
   "metadata": {},
   "source": [
    "Had to copy all images and masks as tiffs to a single pair of folders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7222c258-b901-481e-ac5d-c338a776bbed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X)):\n",
    "    sk.io.imsave(os.path.join('E:/Grainger_Lab/Amber/OIC-74_Zebrafish_RBC_Classification/tiles/All_Imgs/Imgs','Img_0'+str(i)+'.tif'),X[i],check_contrast=False)\n",
    "    sk.io.imsave(os.path.join('E:/Grainger_Lab/Amber/OIC-74_Zebrafish_RBC_Classification/tiles/All_Imgs/Masks','Img_0'+str(i)+'.tif'),Y[i],check_contrast=False)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6158c837-b51e-4d73-85aa-e4b255f7cb16",
   "metadata": {},
   "source": [
    "Read in images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e19a90a3-d5de-42d4-9b85-21406cdac74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfiles = sorted(glob('E:/Grainger_Lab/Amber/OIC-74_Zebrafish_RBC_Classification/tiles/All_Imgs/Imgs/*.tif'))\n",
    "Yfiles = sorted(glob('E:/Grainger_Lab/Amber/OIC-74_Zebrafish_RBC_Classification/tiles/All_Imgs/Masks/*.tif'))\n",
    "#assert all(Path(x).name==Path(y).name for x,y in zip(X,Y)) #added indexing here because the file type is different between the images and the masks, using indexing to match the name of the file without file type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7283c253-6558-4acf-a171-cd341b08e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(map(imread,Xfiles))\n",
    "Y = list(map(imread,Yfiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "02a5f85e-7160-4b5a-829f-0861df295794",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[0:len(X):100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "46683872-b9da-477c-9f39-9fe687301c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y[0:len(Y):100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "33577197-b9bf-461e-b307-9539b7c9ab20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1c989de9-ca00-4c4e-9aac-923c80634ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "46dc5bb5-91ac-4b27-889e-6bde7ebc1b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Check number of channels\n",
    "print(n_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285a9ad4-1c43-4d46-b1a4-bece53309706",
   "metadata": {},
   "source": [
    "Normalize the images, fill possible holes in labels then split into train and validate groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "373b2f1c-785f-4fe1-9e96-ae0fbe58b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing image channels independently.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 121/121 [00:09<00:00, 12.14it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 121/121 [00:02<00:00, 41.94it/s]\n"
     ]
    }
   ],
   "source": [
    "axis_norm = (0,1)   # normalize channels independently\n",
    "# axis_norm = (0,1,2) # normalize channels jointly\n",
    "if n_channel > 1:\n",
    "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "X = [normalize(x,1,99.8,axis=axis_norm) for x in tqdm(X)]\n",
    "Y = [fill_label_holes(y) for y in tqdm(Y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f26a67bd-c58c-4ced-ba72-e1566bbd19da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of images: 121\n",
      "- training:       103\n",
      "- validation:      18\n"
     ]
    }
   ],
   "source": [
    "assert len(X) > 1, \"not enough training data\"\n",
    "rng = np.random.RandomState(42)\n",
    "ind = rng.permutation(len(X))\n",
    "n_val = max(1, int(round(0.15 * len(ind))))\n",
    "ind_train, ind_val = ind[:-n_val], ind[-n_val:]\n",
    "X_val, Y_val = [X[i] for i in ind_val]  , [Y[i] for i in ind_val]\n",
    "X_trn, Y_trn = [X[i] for i in ind_train], [Y[i] for i in ind_train] \n",
    "print('number of images: %3d' % len(X))\n",
    "print('- training:       %3d' % len(X_trn))\n",
    "print('- validation:     %3d' % len(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6119b04-56d7-4424-abbd-b6aa80bad409",
   "metadata": {},
   "source": [
    "Set up hyperparameters for StarDist Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "318e8e18-5a33-49ad-a7af-745da2334853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 is a good default choice (see 1_data.ipynb)\n",
    "n_rays = 32\n",
    "\n",
    "# Use OpenCL-based computations for data generator during training (requires 'gputools')\n",
    "use_gpu = True and gputools_available()\n",
    "\n",
    "# Predict on subsampled grid for increased efficiency and larger field of view\n",
    "grid = (4,4)\n",
    "\n",
    "conf = Config2D (\n",
    "    n_rays       = n_rays,\n",
    "    grid         = grid,\n",
    "    use_gpu      = use_gpu,\n",
    "    n_channel_in = n_channel,\n",
    "    train_patch_size = (512,512),\n",
    "    train_steps_per_epoch = 100,\n",
    "    train_epochs = 400,\n",
    ")\n",
    "#print(conf)\n",
    "#vars(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9e50e69c-015f-4784-b78e-df5b98e389bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default values: prob_thresh=0.5, nms_thresh=0.4.\n"
     ]
    }
   ],
   "source": [
    "model = StarDist2D(conf, name='BloodCells', basedir='models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbccd8ad-5d81-45bf-a8c8-6b1de53c301f",
   "metadata": {},
   "source": [
    "Make sure that the field of view for the network is larger than the objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c82c6900-f44e-419d-8864-3e4cb3d1f54c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "functional.py (238): The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['input']\n",
      "Received: inputs=Tensor(shape=(1, 512, 512, 3))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median object size:      [93.5 97. ]\n",
      "network field of view :  [188 188]\n"
     ]
    }
   ],
   "source": [
    "median_size = calculate_extents(list(Y), np.median)\n",
    "fov = np.array(model._axes_tile_overlap('YX'))\n",
    "print(f\"median object size:      {median_size}\")\n",
    "print(f\"network field of view :  {fov}\")\n",
    "# if any(median_size > fov):\n",
    "#     print(\"WARNING: median object size larger than field of view of the neural network.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ac3fb3-0f39-4a78-a9b5-863cbfaa4a88",
   "metadata": {},
   "source": [
    "Define the augementations to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3a83e6f1-2489-487b-b464-7b9f8f2c8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_fliprot(img, mask): \n",
    "    assert img.ndim >= mask.ndim\n",
    "    axes = tuple(range(mask.ndim))\n",
    "    perm = tuple(np.random.permutation(axes))\n",
    "    img = img.transpose(perm + tuple(range(mask.ndim, img.ndim))) \n",
    "    mask = mask.transpose(perm) \n",
    "    for ax in axes: \n",
    "        if np.random.rand() > 0.5:\n",
    "            img = np.flip(img, axis=ax)\n",
    "            mask = np.flip(mask, axis=ax)\n",
    "    return img, mask \n",
    "\n",
    "def random_intensity_change(img):\n",
    "    img = img*np.random.uniform(0.6,2) + np.random.uniform(-0.2,0.2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def augmenter(x, y):\n",
    "    \"\"\"Augmentation of a single input/label image pair.\n",
    "    x is an input image\n",
    "    y is the corresponding ground-truth label image\n",
    "    \"\"\"\n",
    "    x, y = random_fliprot(x, y)\n",
    "    x = random_intensity_change(x)\n",
    "    # add some gaussian noise\n",
    "    sig = 0.02*np.random.uniform(0,1)\n",
    "    x = x + sig*np.random.normal(0,1,x.shape)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ab663d-4184-47e8-b94e-0ef772383276",
   "metadata": {},
   "source": [
    "Train the model\n",
    "\n",
    "Use `tensorboard --logdir=.` in the command line in the same parent directory as the models (with StarDist env active) to watch live read out of training (could also put in the directory of the parent folder instead of cd to parent directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95d3c59-f6f5-4b30-b509-08c2c5ed7ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "\u001b[1m 52/100\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 628ms/step - dist_dist_iou_metric: 0.0014 - dist_loss: 39.9708 - dist_relevant_mae: 39.9707 - dist_relevant_mse: 2124.5559 - loss: 8.4608 - prob_kld: 0.2969 - prob_loss: 0.4666"
     ]
    }
   ],
   "source": [
    "model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce95d8-93a8-492f-9db2-a93fa151eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimize_thresholds(X_val, Y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StarDistGPU",
   "language": "python",
   "name": "stardistgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
