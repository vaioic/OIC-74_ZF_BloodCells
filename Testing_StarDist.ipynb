{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86f846ab-0754-4e40-8912-3aa9b19edec9",
   "metadata": {},
   "source": [
    "# Testing StarDist network for instance segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c606305e-397e-47b2-8f36-6064372de8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, unicode_literals, absolute_import, division\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"image.interpolation\"] = 'none'\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import skimage as sk\n",
    "from tifffile import imread\n",
    "from csbdeep.utils import Path, normalize\n",
    "import napari\n",
    "import os\n",
    "from stardist import fill_label_holes, random_label_cmap, calculate_extents, gputools_available\n",
    "from stardist.matching import matching, matching_dataset\n",
    "from stardist.models import Config2D, StarDist2D, StarDistData2D\n",
    "\n",
    "np.random.seed(42)\n",
    "lbl_cmap = random_label_cmap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6cf81ea-69dc-47ca-ad8f-0a2dda1cf71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sorted(glob('E:/Grainger_Lab/Amber/OIC-74_Zebrafish_RBC_Classification/tiles/**/imgTiles/*.tif',recursive=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eaa2288e-2e16-465b-a865-323216a5879b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15150"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e19a90a3-d5de-42d4-9b85-21406cdac74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sorted(glob('E:/Grainger_Lab/Amber/OIC-74_Zebrafish_RBC_Classification/tiles/**/imgTiles/*.tif',recursive=True))\n",
    "Y = sorted(glob('E:/Grainger_Lab/Amber/OIC-74_Zebrafish_RBC_Classification/tiles/**/instTiles/*.tif',recursive=True))\n",
    "assert all(Path(x).name==Path(y).name for x,y in zip(X,Y)) #added indexing here because the file type is different between the images and the masks, using indexing to match the name of the file without file type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c600def7-9a91-4693-9ab7-e2fe6899442d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y = sorted(glob('E:/Grainger_Lab/Amber/OIC-74_Zebrafish_RBC_Classification/tiles/2025_01_28__0346-Scene-1-ScanRegion0/instTiles/*.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "24986a01-c5b7-4546-b2f1-2d828c047a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converted all pngs to tiffs\n",
    "for y in Y:\n",
    "    path = os.path.dirname(y)\n",
    "    name = os.path.basename(y)\n",
    "    img = sk.io.imread(y)\n",
    "    sk.io.imsave(os.path.join(path,name[:-4]+'.tif'),img,check_contrast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d520edd5-3fe1-4bb6-86ca-1f067facbbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.view_image(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7283c253-6558-4acf-a171-cd341b08e22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(map(imread,X))\n",
    "Y = list(map(imread,Y))\n",
    "n_channel = 1 if X[0].ndim == 2 else X[0].shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cdbea10d-b2c6-4cc2-af9f-540315ca7e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_labels = []\n",
    "for img in Y:\n",
    "    array = np.array(img)\n",
    "    array = (array * 255).astype(np.uint8)\n",
    "    Y_labels.append(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373b2f1c-785f-4fe1-9e96-ae0fbe58b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing image channels independently.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███████▊                                                                      | 1528/15150 [01:55<17:02, 13.32it/s]"
     ]
    }
   ],
   "source": [
    "axis_norm = (0,1)   # normalize channels independently\n",
    "# axis_norm = (0,1,2) # normalize channels jointly\n",
    "if n_channel > 1:\n",
    "    print(\"Normalizing image channels %s.\" % ('jointly' if axis_norm is None or 2 in axis_norm else 'independently'))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "X = [normalize(x,1,99.8,axis=axis_norm) for x in tqdm(X)]\n",
    "Y = [fill_label_holes(y) for y in tqdm(Y_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9f1c8417-1861-4421-9118-b4390a04a45e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a67bd-c58c-4ced-ba72-e1566bbd19da",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(X) > 1, \"not enough training data\"\n",
    "rng = np.random.RandomState(42)\n",
    "ind = rng.permutation(len(X))\n",
    "n_val = max(1, int(round(0.15 * len(ind))))\n",
    "ind_train, ind_val = ind[:-n_val], ind[-n_val:]\n",
    "X_val, Y_val = [X[i] for i in ind_val]  , [Y_labels[i] for i in ind_val]\n",
    "X_trn, Y_trn = [X[i] for i in ind_train], [Y_labels[i] for i in ind_train] \n",
    "print('number of images: %3d' % len(X))\n",
    "print('- training:       %3d' % len(X_trn))\n",
    "print('- validation:     %3d' % len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318e8e18-5a33-49ad-a7af-745da2334853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32 is a good default choice (see 1_data.ipynb)\n",
    "n_rays = 32\n",
    "\n",
    "# Use OpenCL-based computations for data generator during training (requires 'gputools')\n",
    "use_gpu = True and gputools_available()\n",
    "\n",
    "# Predict on subsampled grid for increased efficiency and larger field of view\n",
    "grid = (2,2)\n",
    "\n",
    "conf = Config2D (\n",
    "    n_rays       = n_rays,\n",
    "    grid         = grid,\n",
    "    use_gpu      = use_gpu,\n",
    "    n_channel_in = n_channel,\n",
    "    train_patch_size = (256,256),\n",
    "    train_steps_per_epoch = 100,\n",
    "    train_epochs = 400,\n",
    ")\n",
    "print(conf)\n",
    "vars(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e50e69c-015f-4784-b78e-df5b98e389bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StarDist2D(conf, name='BloodCells', basedir='models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82c6900-f44e-419d-8864-3e4cb3d1f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_size = calculate_extents(list(Y_labels), np.median)\n",
    "fov = np.array(model._axes_tile_overlap('YX'))\n",
    "print(f\"median object size:      {median_size}\")\n",
    "print(f\"network field of view :  {fov}\")\n",
    "if any(median_size > fov):\n",
    "    print(\"WARNING: median object size larger than field of view of the neural network.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a83e6f1-2489-487b-b464-7b9f8f2c8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_fliprot(img, mask): \n",
    "    assert img.ndim >= mask.ndim\n",
    "    axes = tuple(range(mask.ndim))\n",
    "    perm = tuple(np.random.permutation(axes))\n",
    "    img = img.transpose(perm + tuple(range(mask.ndim, img.ndim))) \n",
    "    mask = mask.transpose(perm) \n",
    "    for ax in axes: \n",
    "        if np.random.rand() > 0.5:\n",
    "            img = np.flip(img, axis=ax)\n",
    "            mask = np.flip(mask, axis=ax)\n",
    "    return img, mask \n",
    "\n",
    "def random_intensity_change(img):\n",
    "    img = img*np.random.uniform(0.6,2) + np.random.uniform(-0.2,0.2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def augmenter(x, y):\n",
    "    \"\"\"Augmentation of a single input/label image pair.\n",
    "    x is an input image\n",
    "    y is the corresponding ground-truth label image\n",
    "    \"\"\"\n",
    "    x, y = random_fliprot(x, y)\n",
    "    x = random_intensity_change(x)\n",
    "    # add some gaussian noise\n",
    "    sig = 0.02*np.random.uniform(0,1)\n",
    "    x = x + sig*np.random.normal(0,1,x.shape)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95d3c59-f6f5-4b30-b509-08c2c5ed7ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(X_trn, Y_trn, validation_data=(X_val,Y_val), augmenter=augmenter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce95d8-93a8-492f-9db2-a93fa151eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.optimize_thresholds(X_val, Y_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StarDistGPU",
   "language": "python",
   "name": "stardistgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
